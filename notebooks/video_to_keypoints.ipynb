{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# from utils.body import BODY_PARTS_NAMES, BODY_CONNECTIONS_DRAW, BODY_CONNECTIONS\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from configs.config import YOLO_MODEL_DIR, YouTube_DIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.set_style('darkgrid')",
   "id": "bae9d7b9115f0315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 载入模型，视频，并创建Supervision注释器\n",
    "model = YOLO(YOLO_MODEL_DIR, task='pose')\n",
    "byte_tracker = sv.ByteTrack()\n",
    "video_path = Path(YouTube_DIR) / 'videos' / 'falls' / 'banana-peel-fall.mp4'\n",
    "print(f'video path: {str(video_path)}')\n",
    "\n",
    "# 读取视频\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file!\")\n",
    "\n",
    "# 获取视频的width height，fps\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f'frame width: {frame_width}')\n",
    "print(f'frame height: {frame_height}')\n",
    "print(f'fps: {fps}')\n",
    "\n",
    "# 进行scale\n",
    "scale_percent = 100\n",
    "width = int(frame_width * scale_percent / 100)\n",
    "height = int(frame_height * scale_percent / 100)\n",
    "\n",
    "print(f'scaled width: {width}')\n",
    "print(f'scaled height: {height}')\n",
    "\n",
    "# 输出路径\n",
    "output_path = Path(\"output\") / \"banana-peel-fall.avi\"\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# 初始化输出视频写入器\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "# ================== 创建 Supervision 注释器 ==================\n",
    "# 创建边界框绘制器\n",
    "bounding_box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "\n",
    "# 创建标签绘制器\n",
    "text_scale = .5\n",
    "text_thickness = 1\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_thickness=text_thickness,\n",
    "    text_scale=text_scale\n",
    ")\n",
    "\n",
    "# 创建轨迹绘制器\n",
    "trace_annotator = sv.TraceAnnotator(thickness=2)"
   ],
   "id": "65cecab110717423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from configs.yolopose_config import BODY_PARTS_NAMES, BODY_CONNECTIONS_DRAW\n",
    "# ========== 封装帧处理函数 ==========\n",
    "def process_frame(frame):\n",
    "    annotated = frame.copy()\n",
    "    # 关键点检测\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    # # 打印所有可用属性\n",
    "    # print(dir(results))\n",
    "    # print('\\n')\n",
    "    # # 查看关键点数据\n",
    "    # print(\"keypoints:\", results.keypoints)\n",
    "    # print('\\n')\n",
    "    #\n",
    "    # # 查看边界框、置信度、类别等（如果检测也输出）\n",
    "    # print(\"boxes:\", results.boxes)\n",
    "    # print('\\n')\n",
    "    #\n",
    "    # # 查看类别名称字典（如 {0: 'person'})\n",
    "    # print(\"names:\", results.names)\n",
    "\n",
    "    if len(results.keypoints.xy) > 0:\n",
    "        # 将 YOLO 推理结果转换为 supervision 的 Detections 格式（包含边界框、置信度、类别ID、关键点等）\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "        # 使用 ByteTrack 更新跟踪状态，为每个检测分配或维持一个 tracker_id（追踪 ID）\n",
    "        detections = byte_tracker.update_with_detections(detections)\n",
    "\n",
    "\n",
    "        # 为每个检测目标生成标签（包含跟踪ID、类别名、置信度）。\n",
    "        labels = [\n",
    "            f'#{tracker_id} {results.names[class_id]} {confidence:.2f}'\n",
    "            for class_id, confidence, tracker_id in zip(\n",
    "                detections.class_id, detections.confidence, detections.tracker_id\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 绘制目标轨迹线（tracking trace）\n",
    "        annotated = trace_annotator.annotate(annotated, detections)\n",
    "        # 绘制边界框（bounding box）\n",
    "        annotated = bounding_box_annotator.annotate(annotated, detections)\n",
    "        # 绘制标签文字（label text）\n",
    "        annotated = label_annotator.annotate(annotated, detections, labels)\n",
    "\n",
    "        for person_idx in range(len(results.keypoints.xy)):\n",
    "            keypoints = results.keypoints.xy[person_idx]\n",
    "            if keypoints.size(0) == 0:\n",
    "                continue\n",
    "            body = {part: keypoints[i] for i, part in enumerate(BODY_PARTS_NAMES)}\n",
    "\n",
    "            for group, (connections, color) in BODY_CONNECTIONS_DRAW.items():\n",
    "                for part_a, part_b in connections:\n",
    "                    x1, y1 = map(int, body[part_a])\n",
    "                    x2, y2 = map(int, body[part_b])\n",
    "                    if x1 == 0 or y1 == 0 or x2 == 0 or y2 == 0:\n",
    "                        continue\n",
    "                    cv2.line(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                for part_a, _ in connections:\n",
    "                    x, y = map(int, body[part_a])\n",
    "                    if x == 0 or y == 0:\n",
    "                        continue\n",
    "                    cv2.circle(annotated, (x, y), 4, color, -1)\n",
    "\n",
    "    return annotated, len(results.keypoints.xy)\n",
    "\n",
    "# 测试 process frame\n",
    "# ret, frame = cap.read()\n",
    "# annotated_frame, person_count = process_frame(frame)"
   ],
   "id": "be5bf4f10ec8a354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video terminado\")\n",
    "        break\n",
    "\n",
    "    # 处理并获取注释帧\n",
    "    annotated_frame, person_count = process_frame(frame)\n",
    "\n",
    "    # Calculate FPS\n",
    "    fps_real = 1 / (time.time() - start_time + 1e-6)\n",
    "\n",
    "    # Agregar texto de información\n",
    "    cv2.putText(annotated_frame, f'{frame_width}x{frame_height}', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, text_scale, (0, 255, 0), text_thickness, cv2.LINE_AA)\n",
    "    cv2.putText(annotated_frame, f'Real: {fps_real:.2f} FPS', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, text_scale, (0, 0, 255), text_thickness, cv2.LINE_AA)\n",
    "    cv2.putText(annotated_frame, f'Personas: {person_count}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, text_scale, (255, 0, 0), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    annotated_frame = cv2.resize(annotated_frame, (width, height))\n",
    "\n",
    "    # 写入视频\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "9063aa1af500e011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_keypoints_from_video(video_path: str, model: YOLO,  sequence_length: int = 20, output_path: str = 'keypoints.npy'):\n",
    "    num_keypoints = 17 * 2\n",
    "    frame_count = 0  # 初始化帧编号\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f'El archivo de video {video_path} no existe')\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_buffer = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break # Video terminado\n",
    "\n",
    "        results = model(frame)[0]\n",
    "        frame_count += 1\n",
    "        print(f\"处理第 {frame_count} 帧\")\n",
    "\n",
    "        if len(results.keypoints.xy) > 0:\n",
    "            keypoints = results.keypoints.xy[0].cpu().numpy().flatten()\n",
    "            if keypoints.shape[0] != num_keypoints:\n",
    "                keypoints = np.pad(keypoints, (0, num_keypoints - keypoints.shape[0]))\n",
    "        else:\n",
    "            # keypoints = np.zeros(num_keypoints, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        keypoints_buffer.append(keypoints)\n",
    "\n",
    "        if len(keypoints_buffer) == sequence_length:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    keypoints_buffer = np.array(keypoints_buffer, dtype=np.float32)\n",
    "    np.save(output_path, keypoints_buffer)\n",
    "    print(f'save to {output_path}')\n",
    "\n",
    "    return keypoints_buffer"
   ],
   "id": "38d4644fbf589d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T06:36:50.442527Z",
     "start_time": "2025-07-15T06:36:49.031135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = Path(\"output\") / \"banana-peel-fall.npy\"\n",
    "\n",
    "# 数据格式: num_frames x num_joints(17) * 2 (x,y)\n",
    "# 没有经过中心化和归一化处理的\n",
    "keypoints_videos = extract_keypoints_from_video(str(video_path), model, sequence_length=400, output_path=str(output_path))\n",
    "print(f'keypoints npy shape: {keypoints_videos.shape}')\n",
    "print(keypoints_videos)"
   ],
   "id": "dbc4049058e75c9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Speed: 10.6ms preprocess, 37.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 1 帧\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 2.1ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 2 帧\n",
      "\n",
      "0: 384x640 1 person, 25.4ms\n",
      "Speed: 9.1ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 3 帧\n",
      "\n",
      "0: 384x640 1 person, 30.2ms\n",
      "Speed: 7.7ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 4 帧\n",
      "\n",
      "0: 384x640 1 person, 45.3ms\n",
      "Speed: 1.9ms preprocess, 45.3ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 5 帧\n",
      "\n",
      "0: 384x640 1 person, 54.7ms\n",
      "Speed: 1.8ms preprocess, 54.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 6 帧\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 7 帧\n",
      "\n",
      "0: 384x640 1 person, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 8 帧\n",
      "\n",
      "0: 384x640 1 person, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 9 帧\n",
      "\n",
      "0: 384x640 1 person, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 10 帧\n",
      "\n",
      "0: 384x640 1 person, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 11 帧\n",
      "\n",
      "0: 384x640 1 person, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 12 帧\n",
      "\n",
      "0: 384x640 1 person, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 13 帧\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 14 帧\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 15 帧\n",
      "\n",
      "0: 384x640 1 person, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 16 帧\n",
      "\n",
      "0: 384x640 1 person, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 17 帧\n",
      "\n",
      "0: 384x640 1 person, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 18 帧\n",
      "\n",
      "0: 384x640 2 persons, 10.3ms\n",
      "Speed: 1.1ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 19 帧\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 20 帧\n",
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 21 帧\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 22 帧\n",
      "\n",
      "0: 384x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 23 帧\n",
      "\n",
      "0: 384x640 1 person, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 24 帧\n",
      "\n",
      "0: 384x640 1 person, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 25 帧\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 26 帧\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 27 帧\n",
      "\n",
      "0: 384x640 1 person, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 28 帧\n",
      "\n",
      "0: 384x640 1 person, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 29 帧\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 30 帧\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 31 帧\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 32 帧\n",
      "\n",
      "0: 384x640 1 person, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 33 帧\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 34 帧\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 35 帧\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 36 帧\n",
      "\n",
      "0: 384x640 1 person, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 37 帧\n",
      "\n",
      "0: 384x640 1 person, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 38 帧\n",
      "\n",
      "0: 384x640 1 person, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 39 帧\n",
      "\n",
      "0: 384x640 1 person, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 40 帧\n",
      "\n",
      "0: 384x640 1 person, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 41 帧\n",
      "\n",
      "0: 384x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 42 帧\n",
      "\n",
      "0: 384x640 1 person, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 43 帧\n",
      "\n",
      "0: 384x640 1 person, 10.7ms\n",
      "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 44 帧\n",
      "\n",
      "0: 384x640 1 person, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 45 帧\n",
      "\n",
      "0: 384x640 1 person, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 46 帧\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 1.3ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 47 帧\n",
      "\n",
      "0: 384x640 1 person, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 48 帧\n",
      "\n",
      "0: 384x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 49 帧\n",
      "\n",
      "0: 384x640 1 person, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 50 帧\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 51 帧\n",
      "\n",
      "0: 384x640 1 person, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 52 帧\n",
      "\n",
      "0: 384x640 1 person, 9.7ms\n",
      "Speed: 1.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 53 帧\n",
      "\n",
      "0: 384x640 1 person, 10.1ms\n",
      "Speed: 1.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 54 帧\n",
      "\n",
      "0: 384x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 55 帧\n",
      "\n",
      "0: 384x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 56 帧\n",
      "\n",
      "0: 384x640 1 person, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 57 帧\n",
      "\n",
      "0: 384x640 1 person, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 58 帧\n",
      "\n",
      "0: 384x640 1 person, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 59 帧\n",
      "\n",
      "0: 384x640 1 person, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 60 帧\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 61 帧\n",
      "\n",
      "0: 384x640 1 person, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 62 帧\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 1.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 63 帧\n",
      "\n",
      "0: 384x640 1 person, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 64 帧\n",
      "\n",
      "0: 384x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 65 帧\n",
      "\n",
      "0: 384x640 1 person, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 66 帧\n",
      "\n",
      "0: 384x640 1 person, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 67 帧\n",
      "\n",
      "0: 384x640 1 person, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 68 帧\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 1.0ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 69 帧\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 70 帧\n",
      "\n",
      "0: 384x640 1 person, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 71 帧\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 72 帧\n",
      "\n",
      "0: 384x640 1 person, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 73 帧\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 74 帧\n",
      "\n",
      "0: 384x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 75 帧\n",
      "\n",
      "0: 384x640 1 person, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "处理第 76 帧\n",
      "save to output\\banana-peel-fall.npy\n",
      "keypoints npy shape: (76, 34)\n",
      "[[     436.97        88.9      436.64 ...      367.34      471.65      375.57]\n",
      " [     436.99      88.934      436.69 ...      367.45      472.28      375.51]\n",
      " [        434      90.212       432.4 ...      343.51      467.15      356.31]\n",
      " ...\n",
      " [     454.04      358.14      451.89 ...      359.48      612.25      377.04]\n",
      " [     453.58      358.22      451.26 ...      370.39      599.11      389.56]\n",
      " [     452.75       357.8      450.03 ...      373.01      590.86      393.92]]\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
